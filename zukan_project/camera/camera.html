<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>動植物識別AR</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.0.0/dist/tf.min.js"></script>
  <script src="https://aframe.io/releases/1.7.0/aframe.min.js"></script>
  <script src="https://unpkg.com/aframe-troika-text/dist/aframe-troika-text.min.js"></script>
  <style>
    body {
      margin: 0;
      overflow: hidden;
    }

    #startScreen {
      position: fixed;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      background: rgba(0, 0, 0, 0.9);
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      z-index: 100;
      color: white;
      font-family: sans-serif;
    }

    #startButton {
      padding: 20px 40px;
      font-size: 20px;
      background-color: #4caf50;
      color: white;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
      margin-top: 20px;
    }

    #startButton:hover {
      background-color: #45a049;
    }

    #webcam {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      z-index: 0;
    }

    #drawingCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      z-index: 5;
      pointer-events: none;
    }
    
    #controlPanel {
      position: absolute;
      bottom: 10px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(255, 255, 255, 0.9);
      padding: 10px;
      border-radius: 8px;
      z-index: 10;
      font-family: sans-serif;
      width: 90%;
      max-width: 500px;
      text-align: center;
      display: none;
      justify-content: space-around;
      gap: 10px;
    }

    #predictButton,
    #saveButton,
    #clearButton {
      padding: 10px 20px;
      font-size: 18px;
      border: none;
      border-radius: 8px;
      color: white;
      cursor: pointer;
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
      transition: background-color 0.3s;
    }

    #predictButton {
      background-color: #4caf50;
    }

    #predictButton:hover {
      background-color: #45a049;
    }

    #predictButton:disabled {
      background-color: #ccc;
      cursor: not-allowed;
    }
    
    #saveButton {
      background-color: #007bff;
    }

    #saveButton:hover {
      background-color: #0056b3;
    }

    #saveButton:disabled {
      background-color: #ccc;
      cursor: not-allowed;
    }

    #clearButton {
      background-color: #f44336;
    }

    #clearButton:hover {
      background-color: #d32f2f;
    }

    #notificationMessage {
      position: absolute;
      top: 20px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(76, 175, 80, 0.95);
      color: white;
      padding: 15px 25px;
      border-radius: 8px;
      font-family: sans-serif;
      font-size: 16px;
      font-weight: bold;
      z-index: 15;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
      display: none;
      max-width: 80%;
      text-align: center;
      animation: slideDown 0.3s ease-out;
    }

    #notificationMessage.error {
      background: rgba(244, 67, 54, 0.95);
    }

    @keyframes slideDown {
      from {
        transform: translateX(-50%) translateY(-20px);
        opacity: 0;
      }
      to {
        transform: translateX(-50%) translateY(0);
        opacity: 1;
      }
    }

    a-scene {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      z-index: 1;
    }
  </style>
</head>
<body>
  <div id="startScreen">
    <h2>動植物識別AR</h2>
    <p>カメラへのアクセスを許可してください</p>
    <button id="startButton">開始</button>
  </div>

  <video id="webcam" autoplay playsinline muted></video>
  <canvas id="drawingCanvas"></canvas>
  <div id="controlPanel">
    <button id="predictButton" disabled>分類する</button>
    <button id="saveButton" disabled>登録する</button>
    <button id="clearButton">消去</button>
  </div>

  <div id="notificationMessage"></div>

  <a-scene embedded vr-mode-ui="enabled:false" ar-mode="false">
    <a-entity id="cameraRig" position="0 0 0">
      <a-entity id="mainCamera" camera look-controls position="0 1.6 0"></a-entity>
    </a-entity>

    <a-assets>
      <a-asset-item id="notojpFont" src="fonts/MPLUSRounded1c-Black.ttf"></a-asset-item>
    </a-assets>

    <a-entity id="infoBubble" visible="false" scale="0.8 0.8 0.8" face-camera-y tail-update>
      <a-plane color="#8b5a2b" width="2.1" height="1.1" position="0 0 -0.005" material="shader: flat; opacity: 1"></a-plane>
      <a-plane color="#34495e" width="2.0" height="1.0" position="0 0 0" material="shader: flat; opacity: 1"></a-plane>
      <a-troika-text id="bubbleText" font="#notojpFont" value="ここに結果が表示されます" font-size="0.07" color="#FFFFFF" textAlign="center" position="0 0 0.01"></a-troika-text>
      <a-box id="tailBlack" color="#000000" depth="0.05" height="0.05" width="0.15" position="0 -0.575 0" visible="true"></a-box>
      <a-box id="tailWhite" color="#FFFFFF" depth="0.05" height="0.05" width="0.45" position="0 -0.525 0" visible="true"></a-box>
    </a-entity>
  </a-scene>

  <script>
    const modelPath = 'model/model.json';
    const classLabels = ['あやめ', 'さくら', 'とんぼ', 'カブトムシ', 'クワガタ'];
    const labelInfo = {
      'あやめ': {
        name: 'あやめ',
        category: 'サンプル',
        description: 'サンプル',
        show3DObject: false,
        model: 'model/model.json'
      },
      'さくら': {
        name: 'さくら',
        category: 'サンプル',
        description: 'サンプル',
        show3DObject: false,
        model: 'model/model.json'
      },
       'とんぼ': {
        name: 'とんぼ',
        category: 'サンプル',
        description: 'サンプル',
        show3DObject: false,
        model: 'model/model.json'
      },
       'カブトムシ': {
        name: 'カブトムシ',
        category: 'サンプル',
        description: 'サンプル',
        show3DObject: false,
        model: 'model/model.json'
      },
       'クワガタ': {
        name: 'クワガタ',
        category: 'サンプル',
        description: 'サンプル',
        show3DObject: false,
        model: 'model/model.json'
      }
    };

    let model;
    const video = document.getElementById('webcam');
    const drawingCanvas = document.getElementById('drawingCanvas');
    const ctx = drawingCanvas.getContext('2d');
    const predictButton = document.getElementById('predictButton');
    const saveButton = document.getElementById('saveButton');
    const clearButton = document.getElementById('clearButton');
    const controlPanel = document.getElementById('controlPanel');
    const scene = document.querySelector('a-scene');
    const infoBubble = document.getElementById('infoBubble');
    const notificationMessage = document.getElementById('notificationMessage');
    const startScreen = document.getElementById('startScreen');
    const startButton = document.getElementById('startButton');
    let isDrawing = false;
    let points = [];
    let identifiedObject = null;
    let lastPrediction = null;

    function showNotification(message, isError = false) {
      notificationMessage.textContent = message;
      notificationMessage.className = isError ? 'error' : '';
      notificationMessage.style.display = 'block';
      
      setTimeout(() => {
        notificationMessage.style.display = 'none';
      }, 3000);
    }

    function resizeCanvas() {
      // use devicePixelRatio to sharpen canvas on high-DPI displays
      const rect = video.getBoundingClientRect();
      const dpr = window.devicePixelRatio || 1;
      drawingCanvas.style.width = rect.width + 'px';
      drawingCanvas.style.height = rect.height + 'px';
      drawingCanvas.width = Math.floor(rect.width * dpr);
      drawingCanvas.height = Math.floor(rect.height * dpr);
      ctx.setTransform(dpr, 0, 0, dpr, 0, 0);
    }
    window.addEventListener('resize', resizeCanvas);
    video.addEventListener('loadedmetadata', resizeCanvas);

    // load model
    tf.loadLayersModel(modelPath).then(m => {
      model = m;
      console.log('Model loaded');
    }).catch(err => {
      console.error('Model load error', err);
      showNotification('モデルの読み込みに失敗しました', true);
    });

    async function setupCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: 'environment'
          },
          audio: false
        });
        video.srcObject = stream;
        
        await new Promise((resolve) => {
          video.addEventListener('loadedmetadata', resolve, { once: true });
        });
        
        startScreen.style.display = 'none';
        await new Promise(resolve => setTimeout(resolve, 1500));
        
        controlPanel.style.display = 'flex';
        drawingCanvas.style.pointerEvents = "auto";
        
      } catch (err) {
        showNotification("カメラへのアクセスを許可してください。", true);
        startScreen.style.display = 'flex';
      }
    }

    startButton.addEventListener('click', () => {
      setupCamera();
    });

    ctx.strokeStyle = '#007bff';
    ctx.lineWidth = 5;
    ctx.lineCap = 'round';
    ctx.lineJoin = 'round';

    drawingCanvas.addEventListener('touchstart', e => {
      if (e.touches.length !== 1) return;
      e.preventDefault();
      isDrawing = true;
      const t = e.touches[0];
      points = [{
        x: t.clientX,
        y: t.clientY
      }];
      ctx.beginPath();
      ctx.moveTo(t.clientX, t.clientY);
    });

    drawingCanvas.addEventListener('touchmove', e => {
      if (!isDrawing || e.touches.length !== 1) return;
      e.preventDefault();
      const t = e.touches[0];
      points.push({
        x: t.clientX,
        y: t.clientY
      });
      ctx.lineTo(t.clientX, t.clientY);
      ctx.stroke();
      predictButton.disabled = false;
    });

    drawingCanvas.addEventListener('touchend', () => {
      isDrawing = false;
      ctx.closePath();
    });

    clearButton.addEventListener('click', () => {
      ctx.clearRect(0, 0, drawingCanvas.width, drawingCanvas.height);
      points = [];
      predictButton.disabled = true;
      saveButton.disabled = true;
      infoBubble.setAttribute('visible', false);
      if (identifiedObject) {
        identifiedObject.parentNode.removeChild(identifiedObject);
        identifiedObject = null;
      }
      lastPrediction = null;
    });

    // Helper: map client (screen) coordinates to video intrinsic pixels
    function clientToVideoCoords(clientX, clientY) {
      const rect = video.getBoundingClientRect();
      const x = (clientX - rect.left) * (video.videoWidth / rect.width);
      const y = (clientY - rect.top) * (video.videoHeight / rect.height);
      return { x, y };
    }

    predictButton.addEventListener('click', async () => {
      if (!model || points.length < 2) return;

      predictButton.disabled = true;
      saveButton.disabled = true;

      // Compute bounding box in client coordinates
      const minX_client = Math.min(...points.map(p => p.x));
      const minY_client = Math.min(...points.map(p => p.y));
      const maxX_client = Math.max(...points.map(p => p.x));
      const maxY_client = Math.max(...points.map(p => p.y));
      let width_client = maxX_client - minX_client;
      let height_client = maxY_client - minY_client;
      if (width_client <= 0 || height_client <= 0) {
        predictButton.disabled = false;
        return;
      }

      // Map to video pixels (intrinsic video resolution)
      const topLeft = clientToVideoCoords(minX_client, minY_client);
      const bottomRight = clientToVideoCoords(maxX_client, maxY_client);
      let videoMinX = Math.max(0, Math.floor(topLeft.x));
      let videoMinY = Math.max(0, Math.floor(topLeft.y));
      let videoMaxX = Math.min(video.videoWidth, Math.floor(bottomRight.x));
      let videoMaxY = Math.min(video.videoHeight, Math.floor(bottomRight.y));
      let videoWidth = videoMaxX - videoMinX;
      let videoHeight = videoMaxY - videoMinY;
      if (videoWidth <= 0 || videoHeight <= 0) {
        predictButton.disabled = false;
        return;
      }

      // Ensure reasonable minimum size
      const MIN_SIZE = 32;
      if (videoWidth < MIN_SIZE || videoHeight < MIN_SIZE) {
        // expand box slightly
        const expand = 20;
        videoMinX = Math.max(0, videoMinX - expand);
        videoMinY = Math.max(0, videoMinY - expand);
        videoMaxX = Math.min(video.videoWidth, videoMaxX + expand);
        videoMaxY = Math.min(video.videoHeight, videoMaxY + expand);
        videoWidth = videoMaxX - videoMinX;
        videoHeight = videoMaxY - videoMinY;
      }

      // Create original crop canvas
      const originalCanvas = document.createElement('canvas');
      originalCanvas.width = videoWidth;
      originalCanvas.height = videoHeight;
      const originalCtx = originalCanvas.getContext('2d');
      originalCtx.drawImage(video, videoMinX, videoMinY, videoWidth, videoHeight, 0, 0, videoWidth, videoHeight);

      // Augmentation & batching strategy:
      // - generate multiple transforms (rotation, flip, brightness)
      // - stack into a batch and run model.predict once for the batch
      const totalSamples = 24; // number of augmented samples
      const inputSize = 224;
      const tensors = [];

      try {
        for (let i = 0; i < totalSamples; i++) {
          const processedCanvas = document.createElement('canvas');
          processedCanvas.width = videoWidth;
          processedCanvas.height = videoHeight;
          const pctx = processedCanvas.getContext('2d');

          // random small rotation
          const rotationAngle = (Math.random() - 0.5) * 14 * Math.PI / 180; // +/-7 deg
          // brightness variation
          const brightness = 1 + (Math.random() - 0.5) * 0.2; // 0.9 - 1.1
          // occasionally flip
          const doFlip = Math.random() < 0.5;

          pctx.save();
          pctx.translate(videoWidth / 2, videoHeight / 2);
          if (doFlip) pctx.scale(-1, 1);
          pctx.rotate(rotationAngle);
          pctx.filter = `brightness(${brightness})`;
          pctx.drawImage(originalCanvas, -videoWidth / 2, -videoHeight / 2, videoWidth, videoHeight);
          pctx.restore();
          pctx.filter = 'none';

          // Resize to model input
          const resizedCanvas = document.createElement('canvas');
          resizedCanvas.width = inputSize;
          resizedCanvas.height = inputSize;
          const rctx = resizedCanvas.getContext('2d');
          // center-crop to square before resizing to preserve aspect ratio
          const side = Math.min(videoWidth, videoHeight);
          const sx = Math.floor((videoWidth - side) / 2);
          const sy = Math.floor((videoHeight - side) / 2);
          rctx.drawImage(processedCanvas, sx, sy, side, side, 0, 0, inputSize, inputSize);

          // Convert to tensor and normalize [0,1]
          const imgTensor = tf.tidy(() => {
            const t = tf.browser.fromPixels(resizedCanvas).toFloat().div(tf.scalar(255));
            return t;
          });
          tensors.push(imgTensor);
        }

        if (tensors.length === 0) {
          predictButton.disabled = false;
          return;
        }

        // Run prediction on batch
        const results = await tf.tidy(async () => {
          const batch = tf.stack(tensors); // shape [N,224,224,3]
          // If model expects different normalization (mean/std), apply here.
          const logits = model.predict(batch);
          // if logits is array / model with outputs as Tensor, handle accordingly
          const probTensor = Array.isArray(logits) ? tf.softmax(logits[0]) : tf.softmax(logits);
          // per-sample top idx
          const perSampleTop = probTensor.argMax(1);
          // average probabilities across samples
          const meanProbs = probTensor.mean(0);
          // return required tensors (we will .array() them outside tidy)
          return {
            meanProbs,
            perSampleTop,
            probTensor
          };
        });

        // Extract arrays (these are plain arrays, tensors inside results were returned out of tidy so they are not disposed yet)
        const meanProbsArr = await results.meanProbs.data(); // Float32Array length == numClasses
        const perSampleTopArr = await results.perSampleTop.data(); // Int32Array length == totalSamples

        // determine top label over mean probs
        let topIndex = 0;
        let topProb = meanProbsArr[0];
        for (let i = 1; i < meanProbsArr.length; i++) {
          if (meanProbsArr[i] > topProb) {
            topProb = meanProbsArr[i];
            topIndex = i;
          }
        }

        // Count how many augmented samples had that label as top prediction
        let topCount = 0;
        for (let i = 0; i < perSampleTopArr.length; i++) {
          if (perSampleTopArr[i] === topIndex) topCount++;
        }

        // Cleanup tensors we created
        tensors.forEach(t => t.dispose());
        // dispose result tensors (they are Tensors from tidy returned - need disposal)
        if (results.meanProbs) results.meanProbs.dispose();
        if (results.perSampleTop) results.perSampleTop.dispose();
        if (results.probTensor) results.probTensor.dispose();

        // Confidence thresholding using averaged probability
        const confidenceThreshold = 0.65; // lowered because we use averaged probs over augmentations
        const finalLabel = (topProb >= confidenceThreshold && classLabels[topIndex]) ? classLabels[topIndex] : null;

        // Remove previous object if any
        if (identifiedObject) {
          identifiedObject.parentNode.removeChild(identifiedObject);
          identifiedObject = null;
        }

        const bubbleText = document.getElementById('bubbleText');

        if (finalLabel) {
          const labelData = labelInfo[finalLabel];
          const template = `なまえ：${labelData.name}\n種類　：${labelData.category}\n説明　：${labelData.description}\n一致回数：${topCount}/${totalSamples}回\n確信度：${(topProb*100).toFixed(1)}%`;
          
          await new Promise(resolve => setTimeout(resolve, 200));
          
          const camera = document.querySelector('#mainCamera');
          const bubble = document.getElementById('infoBubble');
          const bubbleTextEl = document.getElementById('bubbleText');
          
          if (!camera || !camera.object3D) {
            predictButton.disabled = false;
            return;
          }
          
          bubbleTextEl.setAttribute('value', template);
          
          const cameraWorldPosition = new THREE.Vector3();
          camera.object3D.getWorldPosition(cameraWorldPosition);
          
          const infoBubblePosition = new THREE.Vector3(0, 0, -2);
          infoBubblePosition.applyQuaternion(camera.object3D.quaternion);
          infoBubblePosition.add(cameraWorldPosition);
          
          bubble.setAttribute('position', infoBubblePosition);
          bubble.setAttribute('visible', true);

          lastPrediction = {
            label: finalLabel,
            count: topCount,
            total: totalSamples
          };
          saveButton.disabled = false;

          if (labelData.show3DObject) {
            const targetPosition = new THREE.Vector3(0, 0, -1.5);
            targetPosition.applyQuaternion(camera.object3D.quaternion);
            targetPosition.add(camera.object3D.position);

            const newObject = document.createElement('a-entity');
            newObject.setAttribute('id', 'identifiedObject');
            newObject.setAttribute('position', targetPosition.x + ' ' + targetPosition.y + ' ' + targetPosition.z);
            newObject.setAttribute('scale', labelData.scale || '0.5 0.5 0.5');
            if (labelData.model) {
              newObject.setAttribute('gltf-model', `url(${labelData.model})`);
            } else {
              newObject.setAttribute('geometry', 'primitive: box');
              newObject.setAttribute('material', 'color: #4CAF50');
            }
            scene.appendChild(newObject);
            identifiedObject = newObject;

            const objPos = identifiedObject.getAttribute('position');
            const offset = labelData.arOffset || {
              x: 0.3,
              y: 0.5,
              z: 0.1
            };
            bubble.setAttribute('position', {
              x: objPos.x + offset.x,
              y: objPos.y + offset.y,
              z: objPos.z + offset.z
            });
          }
        } else {
          const camera = document.querySelector('#mainCamera');
          if (!camera || !camera.object3D) {
            predictButton.disabled = false;
            return;
          }
          
          infoBubble.setAttribute('visible', true);
          bubbleText.setAttribute('value', `分類できませんでした。`);
          const cameraWorldPosition = new THREE.Vector3();
          camera.object3D.getWorldPosition(cameraWorldPosition);
          const infoBubblePosition = new THREE.Vector3(0, 0, -2);
          infoBubblePosition.applyQuaternion(camera.object3D.quaternion);
          infoBubblePosition.add(cameraWorldPosition);
          infoBubble.setAttribute('position', infoBubblePosition);
        }

      } catch (err) {
        console.error('Prediction error:', err);
        showNotification('分類中にエラーが発生しました', true);
      } finally {
        // clear drawing and restore UI
        ctx.clearRect(0, 0, drawingCanvas.width, drawingCanvas.height);
        points = [];
        predictButton.disabled = false;
      }
    });
    
    saveButton.addEventListener('click', () => {
      if (!lastPrediction) return;
      
      const { label, count, total } = lastPrediction;
      const now = new Date().toISOString();
      const labelData = labelInfo[label];
      const entry = {
        name: labelData.name,
        category: labelData.category,
        description: labelData.description,
        date: now,
        matchCount: count,
        totalSamples: total
      };

      let zukan = JSON.parse(localStorage.getItem('myZukan') || '[]');
      
      const exists = zukan.some(item => item.name === entry.name);
      
      if (!exists) {
        zukan.push(entry);
        localStorage.setItem('myZukan', JSON.stringify(zukan));
        showNotification('「' + labelData.name + '」をマイずかんに登録しました！');
      } else {
        showNotification('「' + labelData.name + '」はすでに登録済みです。', true);
      }
      
      saveButton.disabled = true;
      lastPrediction = null;
    });

    AFRAME.registerComponent('face-camera-y', {
      tick: function() {
        const camera = document.querySelector('#mainCamera');
        const obj3D = this.el.object3D;
        const cameraPos = new THREE.Vector3();
        camera.object3D.getWorldPosition(cameraPos);
        const objPos = new THREE.Vector3();
        obj3D.getWorldPosition(objPos);
        const dir = new THREE.Vector3().subVectors(cameraPos, objPos);
        dir.y = 0;
        dir.normalize();
        obj3D.rotation.y = Math.atan2(dir.x, dir.z);
      }
    });

    AFRAME.registerComponent('tail-update', {
      tick: function() {
        if (!identifiedObject || !infoBubble.getAttribute('visible')) {
          return;
        }

        const bubblePos = new THREE.Vector3();
        infoBubble.object3D.getWorldPosition(bubblePos);
        const targetPos = new THREE.Vector3();
        identifiedObject.object3D.getWorldPosition(targetPos);

        const dir = new THREE.Vector3().subVectors(targetPos, bubblePos);
        dir.y = 0;
        if (dir.length() < 0.001) {
          return;
        }
        dir.normalize();
        const angle = Math.atan2(dir.x, dir.z) * (180 / Math.PI);
        const tailBlack = infoBubble.querySelector('#tailBlack');
        const tailWhite = infoBubble.querySelector('#tailWhite');
        if (tailBlack) tailBlack.setAttribute('rotation', `0 ${angle} 0`);
        if (tailWhite) tailWhite.setAttribute('rotation', `0 ${angle} 0`);
      }
    });
  </script>
</body>
</html>
